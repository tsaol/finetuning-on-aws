{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cc3ce3-e024-4990-b6bb-d22c78514efa",
   "metadata": {},
   "source": [
    "# Using LLama Factory finetune on SageMaker \n",
    "# 2. 使用vLLM进行本地推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ce18b-d8a7-4f31-b8d6-1de1725124af",
   "metadata": {},
   "source": [
    "## 安装依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66561ea-0d2b-440c-ade2-d1820ea01e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm==0.4.3\n",
      "  Downloading vllm-0.4.3-cp310-cp310-manylinux1_x86_64.whl.metadata (7.8 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting cmake>=3.21 (from vllm==0.4.3)\n",
      "  Downloading cmake-3.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm==0.4.3)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (5.9.8)\n",
      "Collecting sentencepiece (from vllm==0.4.3)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (2.32.3)\n",
      "Collecting py-cpuinfo (from vllm==0.4.3)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.40.0 (from vllm==0.4.3)\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers>=0.19.1 (from vllm==0.4.3)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting fastapi (from vllm==0.4.3)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (3.9.5)\n",
      "Collecting openai (from vllm==0.4.3)\n",
      "  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting uvicorn[standard] (from vllm==0.4.3)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (2.6.4)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (0.20.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.4.3)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.4.3)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.10.1 (from vllm==0.4.3)\n",
      "  Downloading lm_format_enforcer-0.10.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines==0.0.34 (from vllm==0.4.3)\n",
      "  Downloading outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (4.10.0)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (3.13.3)\n",
      "Collecting ray>=2.9 (from vllm==0.4.3)\n",
      "  Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from vllm==0.4.3) (12.535.133)\n",
      "Collecting torch==2.3.0 (from vllm==0.4.3)\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting xformers==0.0.26.post1 (from vllm==0.4.3)\n",
      "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting vllm-flash-attn==2.5.8.post2 (from vllm==0.4.3)\n",
      "  Downloading vllm_flash_attn-2.5.8.post2-cp310-cp310-manylinux1_x86_64.whl.metadata (482 bytes)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.1->vllm==0.4.3)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lm-format-enforcer==0.10.1->vllm==0.4.3) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lm-format-enforcer==0.10.1->vllm==0.4.3) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (3.1.3)\n",
      "Collecting lark (from outlines==0.0.34->vllm==0.4.3)\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (2.2.1)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm==0.4.3)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (1.12.0)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (0.59.1)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: referencing in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (0.34.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from outlines==0.0.34->vllm==0.4.3) (4.21.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->vllm==0.4.3)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.3.0->vllm==0.4.3) (12.1.105)\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->vllm==0.4.3)\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->vllm==0.4.3) (12.5.82)\n",
      "Collecting starlette<1.0.0,>=0.30.0 (from prometheus-fastapi-instrumentator>=7.0.0->vllm==0.4.3)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic>=2.0->vllm==0.4.3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic>=2.0->vllm==0.4.3) (2.16.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.4.3) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm==0.4.3)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.4.3) (4.25.3)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ray>=2.9->vllm==0.4.3) (1.4.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.6.0->vllm==0.4.3)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.4.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.4.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.4.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->vllm==0.4.3) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm==0.4.3) (0.23.4)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.40.0->vllm==0.4.3)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.40.0->vllm==0.4.3) (4.66.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.4.3) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.4.3) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.4.3) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->vllm==0.4.3) (4.0.3)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->vllm==0.4.3)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->vllm==0.4.3) (0.27.0)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi->vllm==0.4.3)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->vllm==0.4.3) (5.9.0)\n",
      "Collecting orjson>=3.2.1 (from fastapi->vllm==0.4.3)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->vllm==0.4.3)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.4.3) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm==0.4.3)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.4.3)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.4.3)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.4.3)\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm==0.4.3)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai->vllm==0.4.3) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai->vllm==0.4.3)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai->vllm==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->vllm==0.4.3) (1.2.0)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->vllm==0.4.3)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->vllm==0.4.3)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm==0.4.3) (1.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->outlines==0.0.34->vllm==0.4.3) (2.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->lm-format-enforcer==0.10.1->vllm==0.4.3) (3.1.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm==0.4.3) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm==0.4.3) (0.18.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numba->outlines==0.0.34->vllm==0.4.3) (0.42.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.3.0->vllm==0.4.3) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.4.3)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.4.3)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.4.3)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.4.3) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.4.3)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading vllm-0.4.3-cp310-cp310-manylinux1_x86_64.whl (131.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading vllm_flash_attn-2.5.8.post2-cp310-cp310-manylinux1_x86_64.whl (37.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.1/37.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl (66.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: sentencepiece, py-cpuinfo, ninja, websockets, uvloop, uvicorn, triton, shellingham, safetensors, regex, python-multipart, python-dotenv, orjson, nvidia-nccl-cu12, msgpack, mdurl, lark, interegular, httptools, dnspython, distro, diskcache, cmake, watchfiles, tiktoken, starlette, markdown-it-py, email_validator, torch, tokenizers, rich, prometheus-fastapi-instrumentator, openai, lm-format-enforcer, xformers, vllm-flash-attn, typer, transformers, ray, bitsandbytes, outlines, fastapi-cli, fastapi, vllm\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed bitsandbytes-0.43.1 cmake-3.30.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 interegular-0.3.3 lark-1.1.9 lm-format-enforcer-0.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.0.8 ninja-1.11.1.1 nvidia-nccl-cu12-2.20.5 openai-1.35.13 orjson-3.10.6 outlines-0.0.34 prometheus-fastapi-instrumentator-7.0.0 py-cpuinfo-9.0.0 python-dotenv-1.0.1 python-multipart-0.0.9 ray-2.31.0 regex-2024.5.15 rich-13.7.1 safetensors-0.4.3 sentencepiece-0.2.0 shellingham-1.5.4 starlette-0.37.2 tiktoken-0.7.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.42.3 triton-2.3.0 typer-0.12.3 uvicorn-0.30.1 uvloop-0.19.0 vllm-0.4.3 vllm-flash-attn-2.5.8.post2 watchfiles-0.22.0 websockets-12.0 xformers-0.0.26.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm==0.4.3 bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6195cf1-3605-4d00-b594-071488955a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从s3下载模型文件到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411aa6cd-fb67-4a1e-a397-2082c87ade0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "sagemaker_session =  sagemaker.session.Session() #sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ad0384-68c1-4512-99df-4ac43cf7c215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-342367142984\n"
     ]
    }
   ],
   "source": [
    "print(default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2eafc8-a6b3-49d0-9dee-349243e3888a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/adapter_config.json to local_model/finetuned_model/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/all_results.json to local_model/finetuned_model/all_results.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/README.md to local_model/finetuned_model/checkpoint-160/README.md\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/scheduler.pt to local_model/finetuned_model/checkpoint-160/scheduler.pt\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/rng_state.pth to local_model/finetuned_model/checkpoint-160/rng_state.pth\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/README.md to local_model/finetuned_model/README.md\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/adapter_config.json to local_model/finetuned_model/checkpoint-160/adapter_config.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/special_tokens_map.json to local_model/finetuned_model/checkpoint-160/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/tokenizer_config.json to local_model/finetuned_model/checkpoint-160/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/trainer_state.json to local_model/finetuned_model/checkpoint-160/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/training_args.bin to local_model/finetuned_model/checkpoint-160/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/eval_results.json to local_model/finetuned_model/eval_results.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/runs/Jul10_16-03-29_algo-1-cuufd/events.out.tfevents.1720627442.algo-1-cuufd.227.0 to local_model/finetuned_model/runs/Jul10_16-03-29_algo-1-cuufd/events.out.tfevents.1720627442.algo-1-cuufd.227.0\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/special_tokens_map.json to local_model/finetuned_model/special_tokens_map.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/tokenizer.json to local_model/finetuned_model/checkpoint-160/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/runs/Jul10_16-03-29_algo-1-cuufd/events.out.tfevents.1720628385.algo-1-cuufd.227.1 to local_model/finetuned_model/runs/Jul10_16-03-29_algo-1-cuufd/events.out.tfevents.1720628385.algo-1-cuufd.227.1\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/tokenizer_config.json to local_model/finetuned_model/tokenizer_config.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/train_results.json to local_model/finetuned_model/train_results.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/trainer_log.jsonl to local_model/finetuned_model/trainer_log.jsonl\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/trainer_state.json to local_model/finetuned_model/trainer_state.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/adapter_model.safetensors to local_model/finetuned_model/checkpoint-160/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/training_loss.png to local_model/finetuned_model/training_loss.png\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/training_args.bin to local_model/finetuned_model/training_args.bin\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/adapter_model.safetensors to local_model/finetuned_model/adapter_model.safetensors\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/tokenizer.json to local_model/finetuned_model/tokenizer.json\n",
      "download: s3://sagemaker-us-east-1-342367142984/llama3-8b-qlora/finetuned_model/checkpoint-160/optimizer.pt to local_model/finetuned_model/checkpoint-160/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://{default_bucket}/llama3-8b-qlora/ ./local_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb1132-2f03-4ee8-82c7-1c5aad5cad24",
   "metadata": {},
   "source": [
    "## 加载模型tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8d2745-b522-4f24-98fc-544c59981a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0dda29-eace-4024-baa9-a31cbe38e6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb16486-c28d-4f1a-8252-b65228d191c3",
   "metadata": {},
   "source": [
    "## 加载sample数据，用于对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce41018c-4d78-421b-a989-8a1cd08001c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "# dataset_name = \"zxbsmk/webnovel_cn\"\n",
    "dataset_name = \"hfl/ruozhiba_gpt4\"\n",
    "# Load dataset from the hub\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\",revision='41d2c61beb86c8d4c61916cc656c39d018c40ce5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc42343-da60-47a7-a3c7-5e35bf63c2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4898\n",
      "\n",
      "Training sample:\n",
      "\n",
      "{'input': '', 'instruction': '屁股上不知谁他妈给我扎个窟窿。 今天才发现。吓死我了。我还有救么。？？', 'output': '首先，发现身体上有不明原因的伤口时，不要惊慌失措。你需要尽快洗净伤口、消毒并进行简单的包扎，然后及时去看医生，进行专业的检查和治疗。如果伤口不深且没有感染，在医生的指导下通常是可以治愈的。但如果伤口较深或已有感染，专业的医疗干预是必需的。康复的前提是你需要尽快就医并按照医生的建议进行护理。'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training size: {len(train_dataset)}\")\n",
    "print(\"\\nTraining sample:\\n\")\n",
    "num_samples = 200\n",
    "print(train_dataset[randrange(num_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b51667-4bda-49b3-8453-b6602fc650c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_lora_path = './local_model/finetuned_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a54f14-bc6b-4536-af7e-3f402773fb98",
   "metadata": {},
   "source": [
    "## 使用本地的vLLM部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9259ec-03be-46bf-a7bc-b558b5f4d23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm.lora.request import LoRARequest\n",
    "from vllm import LLM,SamplingParams\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b590cc15-e64f-4da2-abe2-ff42640cab80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'TechxGenus/Meta-Llama-3-8B-Instruct-AWQ'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39cf9c61-4c9c-49af-baac-01aaabf695cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cb2f004b2f44c988ca9d8f665c7cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/885 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-10 16:29:57 config.py:213] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 07-10 16:29:57 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='TechxGenus/Meta-Llama-3-8B-Instruct-AWQ', speculative_config=None, tokenizer='TechxGenus/Meta-Llama-3-8B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=TechxGenus/Meta-Llama-3-8B-Instruct-AWQ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76866aa7908546ca8c1000937bb32a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 16:29:59 weight_utils.py:207] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fd0d94e82f4a86b8e27af420ffe947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1958f148054d7ba165ceb703913b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7a6e80106a4294887921088967ff88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/63.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-10 16:30:13 model_runner.py:146] Loading model weights took 5.3479 GB\n",
      "INFO 07-10 16:30:15 gpu_executor.py:83] # GPU blocks: 6586, # CPU blocks: 2048\n",
      "INFO 07-10 16:30:18 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-10 16:30:18 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-10 16:30:26 model_runner.py:924] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_id,max_model_len=4096,enable_lora=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f3ac73-dea3-413c-957a-dc9a615285e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#测试第一个消息\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "#      {\"role\": \"user\", \"content\": \"你是谁？你是干嘛的\"},\n",
    "# ]\n",
    "\n",
    "# 测试第二个消息\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":\"请始终用中文回答\"},\n",
    "     {\"role\": \"user\", \"content\": \"睡觉时被女鬼压床我该怎么办？\"},\n",
    "]\n",
    "\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236a21c-ce2b-4be6-8ee6-b669dd7a266d",
   "metadata": {},
   "source": [
    "### 使用原始模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86d0f474-83bb-4a03-b2bd-b2c4e3c998b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.44s/it, Generation Speed: 66.20 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n请始终用中文回答<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n睡觉时被女鬼压床我该怎么办？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'\n",
      "Response:\n",
      "'如果你认为自己被女鬼压床，这可能是由于某种原因或 superstition（超stitious）而引起的。以下是一些可能有助的建议：\\n\\n1. **保持理智**：在处理这种情况时，保持理智和冷静是非常重要的。不要让恐惧和担忧控制你的思想。\\n2. **检查环境**：检查你的睡眠环境是否有什么可能会导致这种情况的原因。例如，是否有某种异响或异味？\\n3. **改变睡眠环境**：如果你发现某种原因，尝试改变睡眠环境。例如，移到另一个房间或使用不同的床。\\n4. **寻求支持**：如果你感到非常害怕或不安全，可以寻求支持。和朋友或家人谈论你的感受，或者寻求专业人士的帮助。\\n5. **实践自我保护**：如果你确实感到被女鬼压床，可以尝试一些自我保护的方法。例如，使用护身符、念经祈祷或使用某种保护仪式。\\n\\n需要注意的是，这些方法可能不一定能够解决问题，但它们可以帮助你感到更安全和更有控制感。\\n\\n最后，如果你感到非常害怕或不安全，可以考虑寻求专业人士的帮助，例如心理医生或灵媒。'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0.1, top_p=0.95,max_tokens=512)\n",
    "\n",
    "outputs = llm.generate(inputs, sampling_params)\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt:\\n{prompt!r}\")\n",
    "    print(f\"Response:\\n{generated_text!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c25a2-449e-4af5-b1c8-873c92ad9243",
   "metadata": {},
   "source": [
    "### 加载Lora进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43a3463f-d618-47ec-a618-89719b210134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_lora_path = './local_model/finetuned_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95db9394-c997-48ce-92c3-33381e837833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it, Generation Speed: 62.91 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n请始终用中文回答<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n睡觉时被女鬼压床我该怎么办？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'\n",
      "Response:\n",
      "'睡觉时被女鬼压床这种情况在传统文化中被称为“被压梦”，是一种常见的梦境现象。这种现象通常是由于梦境过于激动人心、情绪过高或是心理压力大的原因。为了避免这种情况，可以通过调整睡眠环境、减少压力、进行放松技巧和理性思考来预防。'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(inputs, sampling_params,lora_request=LoRARequest(\"adapter\", 1, sql_lora_path))\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt:\\n{prompt!r}\")\n",
    "    print(f\"Response:\\n{generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ce7ba-6ff2-45b7-ba9a-ef909a590d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
